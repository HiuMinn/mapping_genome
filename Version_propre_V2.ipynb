{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24a00fa1-72c5-4629-a068-014e0c78f76c",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Projet d’Algorithmique pour la Génomique</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b96ed97-3806-4464-a487-71badaaf1bd3",
   "metadata": {
    "tags": []
   },
   "source": [
    "$\\to$ Développement d’une solution de mapping de données de séquençage à haut-débit sur un génome de référence  \n",
    "Lilian Guitart Arnau, Hieu Minh Dang, Mathis Gallier Jouve et Simon Henninot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d45220-d354-4983-a8c4-62e9ffabc93a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## I. L’algorithme de mapping, sa description et sa complexité"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89066eaa-b1ff-4825-91f3-b94ca8aedcbc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### I.1. Desciption générale de l'algorithme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a36f6ff-7dbc-4262-8a23-18e715aa3231",
   "metadata": {},
   "source": [
    "Nous disposons des séquences complètes des 14 chromosomes et de l'apicoplaste de P. falciparum (parasite responsable du paludisme chez l'homme) sur lequel nous souhaitons mapper des reads obtenus par une technique de séquençage haut-débit.  \n",
    "La méthode naïve consistant à parcourir le génome pour le comparer à chaque read n'est pas envisageable. En effet, la complexité temporelle d'un tel algorithme serait en  $O(N\\_r \\cdot T\\_r \\cdot T\\_g)$ avec :  \n",
    "$N\\_r=$ le nombre de reads  \n",
    "$T\\_r=$ la taille d'un read  \n",
    "$T\\_g=$ la taille du génome complet  \n",
    "Dans notre cas, à raison d'une comparaison de string toutes les 30 ns, cela représente un temps de calcul de l'ordre de $1 500 000 * 100 * 23 000 000 * 30 * 10^{-9} = 1,035 * 10^{8}$ s, c'est-à-dire plus de trois ans.\n",
    "  \n",
    "Pour résoudre ce problème de complexité, nous allons réaliser le mapping d'un read en le divisant en k-mers (sous-séquences de longueurs k) puis en localisant l'ensemble de ces k-mers efficacement sur la transormée de Burrows-Wheeler du génome. \n",
    "Cette stratégie repose sur la possibilité de calculer la BWT du génome via l'algorithme DC3 qui construit la table des suffixes en temps linéaire.  \n",
    "Nous prendrons également en compte le fait q'un k-mer puisse être localisé sur le brin complémentaire inversé, à plusieurs endroits et/ou qu'il puisse y avoir une erreur de séquençage ou une petite mutation.  \n",
    "Le reste des optimisations repose sur la mémorisation de variables globales permettant de ne pas faire les calculs à chaque itérations. On augmente raisonnablement la complexité spaciale pour diminuer grandement la complexité temporelle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ffba5d-c530-4929-9459-96708e8b3ae8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### I.2. Import des librairies :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3e66425-fca8-4174-93ed-2cbdd4f00037",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T23:45:21.374005Z",
     "start_time": "2024-11-17T23:45:21.245511Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from Bio import SeqIO #traitement des fichiers fastq\n",
    "import pysam #traitement des fichiers bam\n",
    "from collections import Counter\n",
    "from bisect import bisect_left #pour la recherche dichotomique rapide\n",
    "import time #permet de calculer les temps d'exécution\n",
    "import cProfile #permet d'analyser finement les temps d'exécution de toutes les fonctions appellées\n",
    "import json #pour stocker les résultats dans un fichier à part entière : resultats.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb700cd-62c0-4a18-b619-d5bda740fd2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### I.3. Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3f203b5-937a-4323-9486-c439cb186176",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:34:31.954627Z",
     "start_time": "2024-11-16T12:34:31.953118Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_fasta_file(fasta_path):\n",
    "    fasta_seq = []\n",
    "    reads = SeqIO.parse(fasta_path, \"fasta\")\n",
    "    for read in reads:\n",
    "        read_seq = str(read.seq)\n",
    "        fasta_seq.append(read_seq)\n",
    "    return fasta_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a0464ed-0ad2-47cb-8d55-7df93ff9fa6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:34:33.307587Z",
     "start_time": "2024-11-16T12:34:33.305776Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "end_of_string = '$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c78eb40-e149-495f-9319-2df7347a66d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:34:34.160224Z",
     "start_time": "2024-11-16T12:34:34.084148Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome = read_fasta_file(\"GCF_000002765.5_GCA_000002765_genomic.fna\")\n",
    "for i in range(len(genome)):\n",
    "    genome[i]=genome[i].upper()+end_of_string # on ne traitera pas ici le cas des minuscules c'est-à-dire des régions de forte simplicité. On ajoute directement le end_of_string nécessaire à la méthode de la BWT\n",
    "len(genome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7422eea-b31b-4f51-b7c6-b94d61c16539",
   "metadata": {},
   "source": [
    "La variable _\"genome\"_ est la liste des 15 chaines de caractères correspondant aux 14 chromosomes de P.falciparum et à son apicoplaste (cf https://en.wikipedia.org/wiki/Plasmodium_falciparum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa69f904-7c10-4d6c-a832-78fecebc2e30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:34:41.045762Z",
     "start_time": "2024-11-16T12:34:35.248744Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Bio.SeqIO.QualityIO.FastqPhredIterator"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reads = SeqIO.parse(\"single_Pfal_dat.fq\", \"fastq\") #Attention : le parcours des reads se fait en les enlevant de reads. Il faut donc bien réexécuter cette ligne à chaque utilisation de la variable. Une copie de cette ligne sera donc dans le main()\n",
    "nb_reads = sum(1 for _ in reads)\n",
    "print(nb_reads)\n",
    "type(reads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f6e4a0-3fe4-4c08-b513-c0f9e145b517",
   "metadata": {},
   "source": [
    "La variable _\"reads\"_ n'est pas convertie en liste pour des raisons de complexité spaciale.  \n",
    "Les reads seront donc traités l'un après l'autre.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a3bdb9-dfee-4f97-a105-a36135680c4b",
   "metadata": {},
   "source": [
    "Les principales variables de l'analyse (potentielement couteuses en temps de calcul) seront calculées puis stockées sous forme de variables globales. Cela ne pose pas de problème de conflit car elle ne dépendent que des données importées et ne changent pas au cours du notebook.  \n",
    "Ci-dessous les premières d'entre-elles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efdca02f-109d-4992-a132-7999ab6c36ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:34:41.048024Z",
     "start_time": "2024-11-16T12:34:41.046549Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A', 'C', 'T', 'G'}\n"
     ]
    }
   ],
   "source": [
    "alphabet = {'A', 'G', 'C', 'T'}\n",
    "print(alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec427f28-63c6-470d-b9cc-936abc2498f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### I.4. Création du Suffix Array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d43c939-ce91-448d-8243-092addc6f80b",
   "metadata": {},
   "source": [
    "On calcule le tableau des suffixes de chaque chromosome du génome en temps linéaire (O(M) avec M la taille du génome complet) grâce à l'algorithme DC3 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2b2e76d-257c-4b4f-93de-210424205a36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:34:41.062807Z",
     "start_time": "2024-11-16T12:34:41.048465Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def DC3(S):\n",
    "\n",
    "    # Étape 0, Création de T\n",
    "    T = []\n",
    "    if len(S) == 0:\n",
    "        return []\n",
    "    if isinstance(S[0], str):  # On vérifie que S contient des chaînes\n",
    "        for c in S:\n",
    "            T.append(ord(c))\n",
    "    else:\n",
    "        T = S.copy()  # Si c'est déjà une liste d'entiers, on la copie\n",
    "    T += [0, 0, 0]  \n",
    "\n",
    "\n",
    "    # Étape 1 :\n",
    "\n",
    "    # Création de P0, P1, P2 et P1_2\n",
    "    P0, P1, P2 = [], [], []\n",
    "    for i in range(len(T) - 2):\n",
    "        if i % 3 == 1:\n",
    "            P1.append(i)\n",
    "        elif i % 3 == 2:\n",
    "            P2.append(i)\n",
    "        elif i % 3 == 0 and i < len(T) - 3:\n",
    "            P0.append(i)\n",
    "    P1_2 = P1 + P2\n",
    "\n",
    "    # Création de R1_2\n",
    "    R1_2 = []\n",
    "    for p in P1_2:\n",
    "        triplet = (T[p], T[p + 1], T[p + 2])\n",
    "        R1_2.append(triplet)\n",
    "\n",
    "    # Tri de R1_2 avec les positions en utilisant le nouveau critère de tri\n",
    "    R1_2_with_p = list(zip(R1_2, P1_2))\n",
    "\n",
    "    def custom_sort(triplet_p):\n",
    "        triplet, p = triplet_p\n",
    "        return triplet + tuple(T[p + 3:p + 10])\n",
    "\n",
    "    R1_2_sorted = sorted(R1_2_with_p, key=custom_sort)\n",
    "\n",
    "    # Création de Index1_2 et Order1_2\n",
    "    rank = 0\n",
    "    prev_key = None\n",
    "    p_to_rank = {}\n",
    "    order_list = []\n",
    "    for triplet_p in R1_2_sorted:\n",
    "        key = custom_sort(triplet_p)\n",
    "        if key != prev_key:\n",
    "            rank += 1\n",
    "        triplet, p = triplet_p\n",
    "        p_to_rank[p] = rank\n",
    "        prev_key = key\n",
    "        order_list.append(rank)\n",
    "    Index1_2 = [p for (triplet, p) in R1_2_sorted]\n",
    "    Order1_2 = order_list\n",
    "\n",
    "    # Création de T'\n",
    "    T_prime = [p_to_rank[p] for p in P1_2]\n",
    "\n",
    "    # Vérification des duplicatas dans Order1_2 pour décider de la récursivité\n",
    "    if len(set(Order1_2)) < len(Order1_2):  # Il y a des duplicatas\n",
    "        Index_prime0_1_2 = DC3(T_prime)\n",
    "        Index1_2 = [P1_2[i] for i in Index_prime0_1_2]\n",
    "        for idx, p in enumerate(Index1_2):\n",
    "            p_to_rank[p] = idx + 1\n",
    "\n",
    "\n",
    "    # Étape 2 : Calcul de R0\n",
    "    R0 = []\n",
    "    for p in P0:\n",
    "        pair = (T[p], p_to_rank.get(p + 1, 0))\n",
    "        R0.append(pair)\n",
    "\n",
    "    # Tri de R0\n",
    "    R0_with_p = list(zip(R0, P0))\n",
    "    R0_sorted = sorted(R0_with_p)\n",
    "    Index0 = [p for (pair, p) in R0_sorted]\n",
    "\n",
    "\n",
    "    # Étape 3 : Fusion de Index0 et Index1_2 pour obtenir le suffix array final\n",
    "\n",
    "    # Fonctions auxiliaires pour la comparaison\n",
    "    def leq(a1, a2, b1, b2):\n",
    "        return a1 < b1 or (a1 == b1 and a2 <= b2)\n",
    "\n",
    "    def leq3(a1, a2, a3, b1, b2, b3):\n",
    "        return a1 < b1 or (a1 == b1 and leq(a2, a3, b2, b3))\n",
    "\n",
    "    SA = []\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < len(Index0) and j < len(Index1_2):\n",
    "        a = Index0[i]\n",
    "        b = Index1_2[j]\n",
    "        if b % 3 == 1:\n",
    "            if leq(T[a], p_to_rank.get(a + 1, 0), T[b], p_to_rank.get(b + 1, 0)):\n",
    "                SA.append(a)\n",
    "                i += 1\n",
    "            else:\n",
    "                SA.append(b)\n",
    "                j += 1\n",
    "        else:\n",
    "            if leq3(T[a], T[a + 1], p_to_rank.get(a + 2, 0), T[b], T[b + 1], p_to_rank.get(b + 2, 0)):\n",
    "                SA.append(a)\n",
    "                i += 1\n",
    "            else:\n",
    "                SA.append(b)\n",
    "                j += 1\n",
    "\n",
    "    # Ajout des indices restants\n",
    "    while i < len(Index0):\n",
    "        SA.append(Index0[i])\n",
    "        i += 1\n",
    "    while j < len(Index1_2):\n",
    "        SA.append(Index1_2[j])\n",
    "        j += 1\n",
    "\n",
    "    # Suppression des indices des sentinelles\n",
    "    SA = [idx for idx in SA if idx < len(T) - 3]\n",
    "    stop = time.time()\n",
    "    return SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "059a9b1b-b251-44c4-8848-39605ba8c91b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:36:59.704607Z",
     "start_time": "2024-11-16T12:34:41.064236Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132.62179613113403\n"
     ]
    }
   ],
   "source": [
    "a = time.time()\n",
    "l_SA = [DC3(chromosome) for chromosome in genome] # ici on ne rajoute pas le end_of_string = '$'\n",
    "b = time.time()\n",
    "print(b-a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba7d629-aa12-4470-999c-94253f417b2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### I.5. Calcul de la BWT du génome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af1fe54-433c-4b90-93d9-2e672b68fbfd",
   "metadata": {},
   "source": [
    "Le calcul efficace de la BWT se fait grâce au tableau des suffixes calculé par l'algorithme DC3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf95c0d5-c90f-428a-b43b-d4ed2c2a3c54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:36:59.707880Z",
     "start_time": "2024-11-16T12:36:59.705806Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def BWT(T,SA=None): #on a déjà rajouté le end_of_string\n",
    "    \"\"\"\n",
    "    Compute the BWT from the suffix table (O(n))\n",
    "\n",
    "    Args:\n",
    "        T (str): string\n",
    "        end_of_string (char): end of string character to append\n",
    "\n",
    "    Return:\n",
    "        bwt (str): BWT\n",
    "    \"\"\"\n",
    "    if SA == None:\n",
    "        SA = DC3(T)\n",
    "    bwt=\"\"\n",
    "    for i in SA:\n",
    "        bwt += T[i-1]\n",
    "    return(bwt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e2a7261-1ba1-46d0-a22a-ff66700701db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:38:21.998063Z",
     "start_time": "2024-11-16T12:38:19.664949Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "l_BWT = [BWT(genome[i],l_SA[i]) for i in range(len(genome))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d994461a4c779f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### I.6. Construction des kmers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18b5aba-3334-4f82-834a-e0b55d32f557",
   "metadata": {},
   "source": [
    "Pour un read donné, on construit la liste de ses kmers simplement comme la liste des sous-mots de longueur k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc3880e410133366",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:36:59.710174Z",
     "start_time": "2024-11-16T12:36:59.708558Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_kmers(read,k):\n",
    "    \"\"\"\n",
    "    construire dictionaire des indexes de kmers (O(T-k))\n",
    "    :param text: genome complet\n",
    "    :param k: longeur de kmers\n",
    "    :return: dictionaire des sous-textes et leurs indices de kmers\n",
    "    #complexite = O(n)\n",
    "    \"\"\"\n",
    "    kmers_list  = []\n",
    "    for i in range(len(read)-k+1):\n",
    "        kmer = read[i:i+k]\n",
    "        kmers_list.append(kmer)\n",
    "    return kmers_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a45dc06-d8a1-4ec5-933d-af42dba5bc2f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### I.7. Mapping des kmers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee867a6e-d889-4aea-a0dd-b2dd77ae642e",
   "metadata": {},
   "source": [
    "Pour réaliser le mapping des kmers de manière efficace, on calcul et on mémorise deux variables globales supplémentaires :\n",
    "- $count$ qui est le dictionnaire dont les clés sont les lettres de l'alphabet et les valeurs le nombre de lettre plus petite dans un chromosome\n",
    "- $occurrence$ qui est le dictionnaire dont les clés sont les lettres de l'alphabet et les valeurs les listes dont l'élément i est le nombre de lettre dans BWT[:(i+1)]  \n",
    "\n",
    "On mémorise ces deux variables pour chaque chromosome sous la forme deux de listes l_count_smaller et l_occurrences (comme pour l_SA et l_BWT)\n",
    "\n",
    "Les fonctions de mapping efficaces des kmers qui suivent ont été inspirées par la correction de TP : Burrows-Wheeler-transform.ipynb de Sergio Peignier (https://sergiopeignier.github.io/string_search.html) et la publication github suivante : https://github.com/kemaleren/bwt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32c45b79-57bf-4e70-b126-15cce436d301",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:36:59.712643Z",
     "start_time": "2024-11-16T12:36:59.711083Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_count_smaller(s):\n",
    "    \"\"\"\n",
    "    compute the number of all the smaller characters in the string (O(n))\n",
    "    :param s (str): \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    K = Counter(s)\n",
    "    cumulated = 0\n",
    "    count_smaller = {}\n",
    "    for letter in sorted(alphabet):\n",
    "        count_smaller[letter] = cumulated\n",
    "        cumulated += K[letter]\n",
    "    return count_smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80461b0e-d4d5-4db5-b9f3-dd66fcfdc65c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:38:28.781209Z",
     "start_time": "2024-11-16T12:38:28.224472Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "l_count_smaller = [compute_count_smaller(L) for L in l_BWT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fc58c68-b538-4ce9-ae41-877b3e869ca4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:38:30.145015Z",
     "start_time": "2024-11-16T12:38:30.141385Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_occurrences(bwt):\n",
    "    \"\"\"\n",
    "    return the occurences of each character in the BWT for each index (O(n))\n",
    "    :param bwt: BWT of the genome\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    occurrences = {letter : [0] for letter in alphabet}\n",
    "    occurrences[bwt[0]] = [1]\n",
    "    for letter in bwt[1:]:\n",
    "        for k, v in occurrences.items():\n",
    "            v.append(v[-1] + (k == letter))\n",
    "    for k, v in occurrences.items():\n",
    "        v.extend([v[-1], 0]) #traitement des cas de dépassement d'indices dans la fonction pattern_matching_bwt\n",
    "    return occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bae43eb-7559-4eab-97a3-79fc197a540c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:38:37.015231Z",
     "start_time": "2024-11-16T12:38:32.044856Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "l_occurrences = [compute_occurrences(L) for L in l_BWT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "d5bbfc582e0b7b4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:38:37.021957Z",
     "start_time": "2024-11-16T12:38:37.020161Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_range(e, f, letter, occ, count_smaller):\n",
    "    \"\"\"\n",
    "    update the range of the substring search based on the occurences dictionary (O(1))\n",
    "    :param e: begin of the range\n",
    "    :param f: end of the range\n",
    "    :param letter: character to search for\n",
    "    :param occ: occurences dictionary\n",
    "    :param count_smaller: dictionary of number of occurences of smaller letters\n",
    "    :return: new begin of the range and new end of the range\n",
    "    \"\"\"\n",
    "    #new_e = count_smaller[letter] + occ[letter][e - 1] + 1\n",
    "    #new_f = count_smaller[letter] + occ[letter][f]\n",
    "    a=count_smaller[letter]\n",
    "    return a + occ[letter][e - 1] + 1, a + occ[letter][f]\n",
    "\n",
    "def pattern_matching_bwt(kmer, n, occ, count_smaller, SA):\n",
    "    \"\"\"\n",
    "    substring search with bwt (O(k))\n",
    "    :param kmer: \n",
    "    :param n: \n",
    "    :param occ: \n",
    "    :param count_smaller: \n",
    "    :param SA: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    results = []\n",
    "    e, f = 0, n - 1\n",
    "    for letter in reversed(kmer):\n",
    "        e, f = update_range(e, f, letter, occ, count_smaller)\n",
    "        if e > f:\n",
    "            return []\n",
    "    results.extend(SA[e:f+1])\n",
    "    return list(dict.fromkeys(SA[e:f + 1])) #plus rapide que sorted(set(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b454543e-914f-4e43-a6b2-5c7a2e61a168",
   "metadata": {},
   "source": [
    "Maintenant que l'on peut mapper un kmer efficacement, on peut construire la liste des maps de tous les kmers d'un read :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "ef77f283-7b35-4819-b1a7-74c56c719cad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:38:37.024744Z",
     "start_time": "2024-11-16T12:38:37.022841Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_kmers(read, n, k, occ, count_smaller, SA):\n",
    "    \"\"\"\n",
    "    query all the kmers of the sequences on the genome (O(kT))\n",
    "    :param read: pattern for query\n",
    "    :param n: \n",
    "    :param k: \n",
    "    :param occ: \n",
    "    :param count_smaller: \n",
    "    :param SA: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    kmers_list = build_kmers(read,k)\n",
    "    res = []\n",
    "    for kmer in kmers_list:\n",
    "        offset = pattern_matching_bwt(kmer, n, occ, count_smaller, SA)\n",
    "        res.append(offset)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c1eea39aa1f7eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### I.8. Analyse des mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bce60a-f28c-4042-946d-495b9fd2225d",
   "metadata": {},
   "source": [
    "On utilise une heuristique pou analyser les listes des maps des kmer d'un read.  \n",
    "On se fixe une variable erreurs_max puis on parcours les différentes positions de départ possibles du read sans dépasser ce seuil (pas forcément en partant des positions du premier kmer qui map). Ensuite, on teste si les kmers suivants mappent aux positions suivantes. On prend alors la meilleure position de départ (si il en existe une sous le seuil d'erreur) et on calcul une distance de hamming entre le read et la portion du génome pour réaliser un calcul exact du pourcentage d'identité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "36488a01-d58c-4243-9567-0ad4d40145a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:38:42.227233Z",
     "start_time": "2024-11-16T12:38:42.224229Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hamming_distance(seq1, seq2):\n",
    "    return sum(1 for a, b in zip(seq1, seq2) if a != b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "6599fbbe-a15d-4242-823e-885308da7da5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:38:46.427428Z",
     "start_time": "2024-11-16T12:38:43.596574Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_in_sorted_list(sorted_list, x):\n",
    "    idx = bisect_left(sorted_list, x) # cette méthode avec la fonction bisect_left est un peu plus rapide qu'une rechecher dichotomique classique\n",
    "    return idx < len(sorted_list) and sorted_list[idx] == x\n",
    "\n",
    "def cherche_succession(idx_kmer, courant, erreurs, k, erreurs_max ,res): #O((T)log(T))\n",
    "    while idx_kmer < len(res) - 1: # on parcours tous les maps \n",
    "        if erreurs > erreurs_max: # cas où on a dépassé l'erreur max\n",
    "            return None\n",
    "        if is_in_sorted_list(res[idx_kmer + 1],courant+1):   # cas où le k_mer suivant a mappé\n",
    "            idx_kmer += k\n",
    "            courant += k\n",
    "        else:   # cas où le k_mer suivant n'a pas mappé et donc qu'il y a un problème à la fin de celui ci\n",
    "            idx_kmer += k # on saute les k kmers suivant qui pourrait comporter d'autres erreurs mais on cherche ici une approximation avant de calculer la distance.\n",
    "            courant += k\n",
    "            erreurs += 1\n",
    "    return erreurs\n",
    "\n",
    "def analyse(read_met,L,k,chromosome,occ,count_smaller,SA,erreurs_max=4):\n",
    "    \"\"\"\n",
    "    O(nT^2log(T))\n",
    "    :param read_met: \n",
    "    :param L: \n",
    "    :param k: \n",
    "    :param chromosome: \n",
    "    :param occ: \n",
    "    :param count_smaller: \n",
    "    :param SA: \n",
    "    :param erreurs_max: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    read = str(read_met.seq)\n",
    "    res = query_kmers(read, len(L), k, occ, count_smaller, SA)\n",
    "    n = len(res)\n",
    "\n",
    "    erreurs = 0\n",
    "    idx_res_first = 0\n",
    "    # Trouver le premier k-mer qui map en comptant les erreurs\n",
    "    while idx_res_first < n and not res[idx_res_first]:\n",
    "        idx_res_first += k # car il se peut que l'erreur soit au k-ieme nucléotide et on ne voudrait pas la compter k fois : la variable erreurs compte le nombre d'erreur minimal de la succession en cours de construction\n",
    "        erreurs += 1\n",
    "        if erreurs > erreurs_max:\n",
    "            return 0,None\n",
    "\n",
    "    best_erreurs = erreurs_max\n",
    "    best_start = None\n",
    "    \n",
    "    # Parcours des positions de départ possibles\n",
    "    max_idx_res = min(idx_res_first + erreurs_max - erreurs, n)\n",
    "    for i in range(idx_res_first, max_idx_res): #pire cas : T-k+1\n",
    "        for courant in res[i]: # pire cas : n-T+1\n",
    "            result = cherche_succession(i, courant, erreurs+i, k, erreurs_max ,res) #O((T)log(T))\n",
    "            if result != None:\n",
    "                current_erreurs = result\n",
    "                if current_erreurs < best_erreurs:\n",
    "                    best_erreurs = current_erreurs\n",
    "                    best_start = courant-i\n",
    "                    \n",
    "    if best_erreurs >= erreurs_max:\n",
    "        return 0,None\n",
    "    # Une fois que l'on pense avoir trouver un candidat par les approximations ci-dessus, on réalise une vraie \n",
    "    # distance pour vérifier (il ne faut donc pas qu'elle soit réalisée trop souvent pour des problème de complexité)\n",
    "    m=len(read)\n",
    "    identity = int(100*(m - hamming_distance(read,chromosome[best_start:best_start+m]))/m) #O(log(T))\n",
    "    return identity,best_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2937d8c0-8a83-47b0-8e63-210fe070c6b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### I.9. Fonction principale et construction du tableau des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db5f111-e282-4d2c-9aea-e83542a4319f",
   "metadata": {},
   "source": [
    "La taille des kmers a été déterminé empiriquement par tests. Un trop petit k impliquerait que les kmers mappent trop souvent. Inversement, un trop grand k impliquerait un trop petit nombre de matches et donc de ne rien détecter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac80091f-65b4-4439-aa89-37b665baa1fe",
   "metadata": {},
   "source": [
    "Toujours pour des raisons de complexité temporelle, lors du parcours des chromosomes dans la fonction main, on va considérer un read seulement s'il n'a pas déjà été bien mapé sur un chromosome précédent (ie à plus de 98% d'identité)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62cc66c-8fad-441b-b34c-6a8bd71bfe9d",
   "metadata": {},
   "source": [
    "Les résultats seront stocker dans un dictionnaire similaire à celui correspondant au fichier bam (cf. partie III) mais aussi dans un fichier à part entière nommé $resultats.json$.  \n",
    "(Une copie de ce fichier des résultats nommé $resultats\\_copie.json$ est déjà enregistré dans le dossier de ce notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "c1af8c88-ca9a-4ab4-a285-8aab9adf0edd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:38:51.860905Z",
     "start_time": "2024-11-16T12:38:51.856623Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(genome=genome,k=20):\n",
    "    resultats_dict = {}\n",
    "    map_ok=[False for i in range(nb_reads)]\n",
    "    for i in range(len(genome)): #15 chromosomes \n",
    "        start = time.time()\n",
    "        reads = SeqIO.parse(\"single_Pfal_dat.fq\", \"fastq\") #Lors du parcours des reads, ceux-ci sont supprimés de la variable. On la redéfinit donc pour chaque chromosome\n",
    "        chromosome = genome[i]\n",
    "        SA = l_SA[i]\n",
    "        L = l_BWT[i]\n",
    "        occ = l_occurrences[i]\n",
    "        count_smaller = l_count_smaller[i]\n",
    "        j=0\n",
    "        for read in reads: #N reads => O(nNT^2log(T))\n",
    "            name = read.name\n",
    "            if not map_ok[j] :  #Si le read a déjà été correctement mappé, on ne cherche pas d'autres positions\n",
    "                identity,position = analyse(read,L,k,chromosome,occ,count_smaller,SA) #O(nT^2log(T))\n",
    "                if identity>=98:\n",
    "                    map_ok[j]=True\n",
    "                if not name in resultats_dict.keys() or identity>resultats_dict[name][\"identity\"] :\n",
    "                    resultats_dict[name] = {\"sequence\": str(read.seq),      # NB : name == id donc on considère seulement le name qui est donc un identifiant\n",
    "                                            \"position\": position,\n",
    "                                            \"identity\": identity,\n",
    "                                            \"chromosome\": i,\n",
    "                                            \"reversed_strand\": False}\n",
    "                identity,position = analyse(read.reverse_complement(),L,k,chromosome,occ,count_smaller,SA)\n",
    "                if not name in resultats_dict.keys() or identity>resultats_dict[name][\"identity\"] :\n",
    "                    resultats_dict[name] = {\"sequence\": str(read.reverse_complement().seq),\n",
    "                                            \"position\": position,\n",
    "                                            \"identity\": identity,\n",
    "                                            \"chromosome\": i,\n",
    "                                            \"reversed_strand\": True}\n",
    "            j+=1\n",
    "        t = time.time()-start\n",
    "        if i==14:\n",
    "            print(\"apicoplaste traité en\",int(t//60),\"min\",int(round((time.time()-start)%60,0)),\"s\")\n",
    "        else :\n",
    "            print(\"chromosome\",i+1,\"traité en\",int(t//60),\"min\",int(round((time.time()-start)%60,0)),\"s\")\n",
    "    \n",
    "    #enregistrement des résultats dans un fichier à part entière\n",
    "    with open(\"resultats.json\", \"w\", encoding=\"utf-8\") as fichier:\n",
    "        json.dump(resultats_dict, fichier, indent=4, ensure_ascii=False)\n",
    "        \n",
    "    return resultats_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4fabd7-c0ab-4d87-af86-c76ced83c67b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### I.10. Calcul de la complexité pire-cas de l'algorihme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58fb7ea-9a4b-48bd-bca0-5ee460297e3d",
   "metadata": {},
   "source": [
    "On avait noté :  \n",
    "$N\\_r=$ le nombre de reads  \n",
    "$T\\_r=$ la taille d'un read  \n",
    "$T\\_g=$ la taille du génome complet  \n",
    "$k=$ la longeur d'un kmer  \n",
    "On note également :  \n",
    "$N\\_c=$ le nombre de chromosome\n",
    "$T\\_c=$ la taille moyenne d'un chromosome\n",
    "\n",
    "\n",
    "Pour des raisons de praticité, des variables globales ont été pré-calculées, en particulier les suffix-arrays (l_SA) et les BWT (l_bwt) de chaque chromosome. Ici, les complexités des fonctions qui calculent ces variables sont DC3 en $O(N\\_c \\cdot T\\_c) = O(T\\_g)$ et BWT en $O(N\\_c \\cdot T\\_c) = O(T\\_g)$.  \n",
    "Aussi, les variables l_count_smaller et l_occurrences ont été calculées par les fonctions $compute_count_smaller()$ en $O(N\\_c \\cdot T\\_c) = O(T\\_g)$ et $compute_occurrences()$ en $O(N\\_c \\cdot T\\_c) = O(T\\_g)$.\n",
    "Les précalculs admettent donc une complexité temporelle en $O(T\\_g)$.  \n",
    "\n",
    "La fonction $pattern\\_matching\\_bwt()$ admet une complexité temporelle en $O(k \\cdot log(T\\_c))$ donc la fonction $query_kmer()$ est en $O(T\\_r \\cdot k \\cdot log(T\\_c))$.  \n",
    "De plus, la $fonction chercher\\_succession()$ a une complexité de $O(T\\_r \\cdot log(T\\_r))$.  \n",
    "Ainsi, la fonction $analyse()$ admet une complexité de $O(k \\cdot T\\_r^3 \\cdot log(T\\_r) \\cdot log(T\\_c))$.  \n",
    "La fonction $main()$ parcourt dans le pire des cas les $N\\_r$ reads pour chaque chromosome et appelle la fonction $analyse()$ à chaque itération. Elle a donc une complexité temporelle pire cas en $O(N\\_c \\cdot N\\_r \\cdot k \\cdot T\\_r^3 \\cdot log(T\\_r) \\cdot log(T\\_c))$.\n",
    "Le nombre de chromosome étant majoré, on peut réécrire cette complexité comme un $O(N\\_r \\cdot k \\cdot T\\_r^3 \\cdot log(T\\_r) \\cdot log(T\\_g))$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744fd811-a71f-4e3a-a535-46d87d0d39e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## II. Exécution sur le jeu de données simulé et évaluation du temps de calcul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "f15838ee-3fe3-40c2-b1d7-95fe90e90212",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T14:28:45.548530Z",
     "start_time": "2024-11-16T12:38:54.864927Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chromosome 1 traité en 14.97 min\n",
      "chromosome 2 traité en 18.06 min\n",
      "chromosome 3 traité en 18.62 min\n",
      "chromosome 4 traité en 17.93 min\n",
      "chromosome 5 traité en 20.48 min\n",
      "chromosome 6 traité en 18.13 min\n",
      "chromosome 7 traité en 16.31 min\n",
      "chromosome 8 traité en 16.44 min\n",
      "chromosome 9 traité en 16.65 min\n",
      "chromosome 10 traité en 15.33 min\n",
      "chromosome 11 traité en 17.19 min\n",
      "chromosome 12 traité en 16.03 min\n",
      "chromosome 13 traité en 15.83 min\n",
      "chromosome 14 traité en 14.51 min\n",
      "chromosome 15 traité en 1.51 min\n",
      "238.08559790849685 min d'exécution au totale\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "resultats = main()\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac5cfdae-85d8-4d55-921a-2348b244f4c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mint\u001b[39m((stop\u001b[38;5;241m-\u001b[39mstart)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3600\u001b[39m),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mint\u001b[39m(((stop\u001b[38;5;241m-\u001b[39mstart)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m)\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m60\u001b[39m),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin d\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexécution au totale\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "print(int((stop-start)//3600),'h',int(((stop-start)/60)%60),\"min d'exécution au totale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "a1761e7f-6dd4-4f1d-8250-02879e3c6c42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cProfile.run(\"main()\",sort=\"cumulative\") #permet de calculer le temps d'exécution de toutes les fonctions appelées si besoin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8951df35-c84c-4881-96c4-de4655405c06",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## III. Résultats obtenus "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fa8b97-f44e-4c23-a614-8ad058319bfe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### III.1. Explication du protocole expérimental de comparaison à la vérité terrain (fichier BAM)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1283ee8a-a783-483e-973e-fe1ae196a974",
   "metadata": {},
   "source": [
    "Le protocole expérimental de comparaison à la vérité terrain passe par la lecture des résultats attendus notés dans le fichier BAM. Pour cela, lors du mapping de chaque read, on note dans un tableau résultat le numéro du read, sa position, sa qualité ainsi que s'il se trouve sur le brin complémentaire ou non.  \n",
    "Les reads sont comparés avec la référence  en calculant la précision, la sensiblité et donc le F1-score. Ici, on considère que si le read a été bien trouvé à une position correct mais le nombre d'identité est faux, le read est un faux négatif. Il faut donc exact au niveau de position et de qualité (identity) pour être considéré comme un vrai positif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "173c3d22-c762-4522-9e2f-93eea15b2365",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T01:19:19.022721Z",
     "start_time": "2024-11-18T01:19:19.015817Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_bam_file(bam_path):\n",
    "    \"\"\"\n",
    "    lecture de fichier bam (O(1))\n",
    "    :param bam_path: \n",
    "    :return: dictionaire des informations de chaque read dans le fichier bam\n",
    "    \"\"\"\n",
    "    def calculate_identity(cigar):\n",
    "        matches = 0\n",
    "        mismatches = 0\n",
    "        total_length = 0\n",
    "        import re\n",
    "        operations = re.findall(r\"(\\d+)([=X])\", cigar)\n",
    "\n",
    "        for length, op in operations:\n",
    "            length = int(length)\n",
    "            if op == \"=\":\n",
    "                matches += length\n",
    "            elif op == \"X\":\n",
    "                mismatches += length\n",
    "\n",
    "            total_length += length\n",
    "\n",
    "        \n",
    "        if total_length > 0:\n",
    "            identity = int(100* matches / total_length)\n",
    "            return identity\n",
    "        else:\n",
    "            return 0\n",
    "    bam_info = {}\n",
    "    bam_name = []\n",
    "    bam_file = pysam.AlignmentFile(bam_path, \"rb\")\n",
    "    for read in bam_file:\n",
    "        read_name = read.query_name\n",
    "        read_seq = read.query_sequence\n",
    "        read_position = read.reference_start\n",
    "        read_is_reverse = read.is_reverse\n",
    "        read_chromosome = read.reference_name\n",
    "        cigar = read.cigarstring\n",
    "\n",
    "        align_length = read.query_alignment_length\n",
    "\n",
    "\n",
    "        bam_info[read_name] = {\"sequence\": read_seq,\n",
    "                               \"position\": read_position,\n",
    "                               \"identity\": calculate_identity(cigar),\n",
    "                               \"chromosome\": read_chromosome,\n",
    "                               \"reversed_strand\": read_is_reverse}  #true if seq is reversed trand\n",
    "        bam_name.append(read_name)\n",
    "    bam_file.close()\n",
    "    return bam_info,bam_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8be1222f-3650-497b-b0b9-e4accfbeaa0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T01:24:28.353920Z",
     "start_time": "2024-11-18T01:24:28.348492Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_result(resultats_dict, bam_path):\n",
    "    \"\"\"\n",
    "    Analyse des résultats trouvés face au fichier BAM \n",
    "    \n",
    "    Args:\n",
    "        reads : object iterable de fastq\n",
    "        resultats_dict : dictionnaire des résultats\n",
    "        bam_path (str): lien du fichier BAM\n",
    "    \"\"\"\n",
    "    \n",
    "    bam_info, bam_name = read_bam_file(bam_path)\n",
    "    TP = FP = FN = 0\n",
    "    TTP =quality_faux =0 #correct position, false in quality\n",
    "    for read_name,read_res in resultats_dict.items() :\n",
    "        if read_res[\"position\"]: #if read is found\n",
    "            \n",
    "            if read_res[\"position\"] == bam_info[read_name][\"position\"]:\n",
    "                TP += 1\n",
    "                TTP += 1\n",
    "                if read_res[\"identity\"] != bam_info[read_name][\"identity\"]:\n",
    "                    FP += 1\n",
    "                    TP -=1\n",
    "                    quality_faux += 1\n",
    "            else:\n",
    "                FP+=1\n",
    "        elif not read_res[\"position\"] and bam_info[read_name][\"position\"]:\n",
    "            FN +=1\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    f1_score = 2*precision*recall/(precision+recall)\n",
    "    print(f\"Nombre de position correcte trouvée : {TTP} ({TTP/len(resultats_dict)*100:.2f}%), où il y a {TP} ({TP/len(resultats_dict)*100:.2f}%) vrais positives\")\n",
    "    print(f\"Nombre de faux positive : {FP} ({FP/len(resultats_dict)*100:.2f}%), dont {quality_faux} ({quality_faux/len(resultats_dict)*100:.2f}%) sont trouvés à bonne position mais faux en l'identité\")\n",
    "    print(f\"Nombre de read pas trouvé (faux négative) : {FN} ({FN/len(resultats_dict)*100:.2f}%), alors qu'ils existe dans le genome\")\n",
    "    print(f\"les mappes donne un résultats avec la précision de {precision} et la sensibilité {recall} dans {len(resultats_dict)} éléments\")\n",
    "    print(f\"F1 score : {f1_score}\")\n",
    "    print(\"Note : Les pourcentages sont par rapport au nombre total de read \")\n",
    "    return precision, recall, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47de4a5e-f9a2-4d24-befb-d8b81f1a214c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### III.2. Analyse des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe0f492ef591e6fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T01:19:29.009226Z",
     "start_time": "2024-11-18T01:19:25.283406Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bam_info,bam_name = read_bam_file(\"single_Pfal_dat.bam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2a4f71512f1cdbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T01:20:24.935902Z",
     "start_time": "2024-11-18T01:20:24.932388Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2862965\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "print(bam_info[\"NC_037283.1-72168\"][\"position\"])\n",
    "print(bam_info[\"NC_037283.1-72168\"][\"identity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2383532-1798-4ce6-961f-b167eff625b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T23:51:38.523912Z",
     "start_time": "2024-11-17T23:51:36.866247Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "resultats_path = \"./resultats_copie.json\"\n",
    "with open(resultats_path, \"r\", encoding=\"utf-8\") as fichier:\n",
    "    resultats_dict = json.load(fichier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d70a7ea3f17f83c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T01:24:35.474986Z",
     "start_time": "2024-11-18T01:24:31.515326Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de position correcte trouvée : 1233597 (82.24%), où il y a 1233514 (82.23%) vrais positives\n",
      "Nombre de faux positive : 103549 (6.90%), dont 83 (0.01%) sont trouvés à bonne position mais faux en l'identité\n",
      "Nombre de read pas trouvé (faux négative) : 162934 (10.86%), alors qu'ils existe dans le genome\n",
      "les mappes donne un résultats avec la précision de 0.9225548833525421 et la sensibilité 0.8833225440546301 dans 1500000 éléments\n",
      "F1 score : 0.9025125561960424\n",
      "Note : Les pourcentages sont par rapport au nombre total de read \n"
     ]
    }
   ],
   "source": [
    "comparaison = test_result(resultats_dict, \"single_Pfal_dat.bam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfcdf1a-942a-4f7b-89b9-1011b22321b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## IV. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2860a800-309d-41c7-84f8-245ac9b59cd2",
   "metadata": {},
   "source": [
    "Notre algorithme a significativement amélioré la complexité de la recherche de séquences dans les grands génomes par rapport aux méthodes naïves. Il est capable d'effectuer un mapping correct pour jusqu'à 80 % (précision à 0.9) des séquences. En revanche, cette méthode ainsi que l'analyse des résultats des k-mers sont approximatives, ce qui engendre une variance dans les résultats de recherche.  \n",
    "Malgré une complexité temporelle en $O(N\\_r \\cdot k \\cdot T\\_r^3 \\cdot log(T\\_r) \\cdot log(T\\_g))$, la fonction $main()$ s'exécute en environ 4h. Cela peut s'expliquer par des grandes valeurs de constantes dans ce \"grand O\". Une piste d'amélioration serait donc de faire diminuer ces constantes via des optimisations de la structure du code ou des types d'objet utilisé."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
